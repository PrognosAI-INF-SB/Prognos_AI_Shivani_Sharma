{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000b97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"processed\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e0411e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time        object\n",
      "SensorA    float64\n",
      "SensorB    float64\n",
      "SensorC    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84c384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfebebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SensorA    137\n",
      "SensorB    235\n",
      "SensorC     48\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "df.fillna(method='ffill', inplace=True)  # forward fill NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c308cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scaling done, shape: (1440, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = df.iloc[:, :-1].values  # all features except target\n",
    "y = df.iloc[:, -1].values   # last column = RUL\n",
    "\n",
    "# Ensure numeric and no NaN\n",
    "X = X.astype(float)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"âœ… Scaling done, shape:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4d78c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scaler saved at models_m2\\scaler_fd1_milestone4.save\n",
      "âœ… Data ready: X_train=(1128, 30, 2), X_val=(282, 30, 2)\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 128)           67072     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 30, 128)           512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119361 (466.25 KB)\n",
      "Trainable params: 118977 (464.75 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "18/18 [==============================] - 14s 223ms/step - loss: 38.8618 - mae: 5.8738 - val_loss: 71.6658 - val_mae: 8.3539\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 108ms/step - loss: 15.1355 - mae: 3.4924 - val_loss: 49.8833 - val_mae: 6.9091\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 5.2877 - mae: 1.8517 - val_loss: 28.8081 - val_mae: 5.1756\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 2.9987 - mae: 1.3678 - val_loss: 26.9735 - val_mae: 4.9939\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 3.1708 - mae: 1.4160 - val_loss: 28.3345 - val_mae: 5.1214\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.8034 - mae: 1.3533 - val_loss: 19.9932 - val_mae: 4.2245\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 3.0127 - mae: 1.3970 - val_loss: 19.2527 - val_mae: 4.1369\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 2.9118 - mae: 1.3740 - val_loss: 18.3804 - val_mae: 4.0129\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 2.4735 - mae: 1.2546 - val_loss: 17.6199 - val_mae: 3.9037\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 2.8244 - mae: 1.3309 - val_loss: 15.1834 - val_mae: 3.5698\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 2.6819 - mae: 1.2973 - val_loss: 14.2096 - val_mae: 3.3956\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 2.5498 - mae: 1.2703 - val_loss: 10.5441 - val_mae: 2.8431\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 2.4573 - mae: 1.2628 - val_loss: 5.7633 - val_mae: 2.0071\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.5017 - mae: 1.2742 - val_loss: 5.9729 - val_mae: 2.0147\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.5380 - mae: 1.2788 - val_loss: 5.3784 - val_mae: 1.9203\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.3355 - mae: 1.2376 - val_loss: 4.6444 - val_mae: 1.7614\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.4263 - mae: 1.2439 - val_loss: 3.1110 - val_mae: 1.4400\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 2.6453 - mae: 1.2936 - val_loss: 2.8153 - val_mae: 1.3679\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 2.2124 - mae: 1.2047 - val_loss: 2.8247 - val_mae: 1.3644\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.1795 - mae: 1.1892 - val_loss: 2.2645 - val_mae: 1.2249\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 2.2143 - mae: 1.1981 - val_loss: 2.2260 - val_mae: 1.2158\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.0703 - mae: 1.1627 - val_loss: 2.2186 - val_mae: 1.2176\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 2.3229 - mae: 1.2133 - val_loss: 2.0664 - val_mae: 1.1797\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 2.1753 - mae: 1.1967 - val_loss: 2.4316 - val_mae: 1.2591\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 2.2566 - mae: 1.1988 - val_loss: 2.2603 - val_mae: 1.1892\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.2879 - mae: 1.2254 - val_loss: 2.4136 - val_mae: 1.2344\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2739 - mae: 1.2106 - val_loss: 2.4868 - val_mae: 1.2301\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.2520 - mae: 1.1881 - val_loss: 2.4642 - val_mae: 1.2466\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 2.1825 - mae: 1.1829 - val_loss: 2.0536 - val_mae: 1.1400\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 2.0673 - mae: 1.1613 - val_loss: 3.0517 - val_mae: 1.3820\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 2.0353 - mae: 1.1658 - val_loss: 2.6438 - val_mae: 1.2742\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 2.1773 - mae: 1.1939 - val_loss: 2.4100 - val_mae: 1.2146\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.9774 - mae: 1.1380 - val_loss: 2.5539 - val_mae: 1.2538\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 2.0254 - mae: 1.1513 - val_loss: 2.7559 - val_mae: 1.3050\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.9571 - mae: 1.1123 - val_loss: 2.7364 - val_mae: 1.2997\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 2.1842 - mae: 1.1819 - val_loss: 2.8562 - val_mae: 1.3321\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 2.0243 - mae: 1.1501 - val_loss: 2.9396 - val_mae: 1.3559\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 2.0255 - mae: 1.1352 - val_loss: 2.7646 - val_mae: 1.3135\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 2.0705 - mae: 1.1498 - val_loss: 2.3344 - val_mae: 1.2364\n",
      "âœ… Model saved at models_m2\\optimized_fd1_milestone4.h5\n",
      "9/9 [==============================] - 2s 24ms/step\n",
      "\n",
      "ðŸ”¹ Model Evaluation â€” FD001\n",
      "RMSE : 1.4330\n",
      "MAE  : 1.1400\n",
      "RÂ² Score : -0.1580\n",
      "Approx. Accuracy : 88.66%\n",
      "ðŸ“Š Metrics saved to results\n",
      "ðŸ“¢ Alerts saved to results\n",
      "   Sample_Index  Predicted_RUL Alert_Level\n",
      "0             0       9.154698    CRITICAL\n",
      "1             1       9.142966    CRITICAL\n",
      "2             2       9.094440    CRITICAL\n",
      "3             3       9.054718    CRITICAL\n",
      "4             4       9.024261    CRITICAL\n",
      "5             5       8.991160    CRITICAL\n",
      "6             6       9.008416    CRITICAL\n",
      "7             7       9.041261    CRITICAL\n",
      "8             8       9.089334    CRITICAL\n",
      "9             9       9.102527    CRITICAL\n"
     ]
    }
   ],
   "source": [
    "# milestone4_full_ready.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import joblib\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "fd_number = 1\n",
    "window_size = 30\n",
    "data_file = \"sensor_data.csv\"\n",
    "\n",
    "processed_dir = \"processed\"\n",
    "model_dir = \"models_m2\"\n",
    "results_dir = \"results\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(model_dir, f\"optimized_fd{fd_number}_milestone4.h5\")\n",
    "scaler_path = os.path.join(model_dir, f\"scaler_fd{fd_number}_milestone4.save\")\n",
    "\n",
    "# ------------------ LOAD CSV ------------------\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Keep only numeric columns\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "df.fillna(method='ffill', inplace=True)  # forward fill NaN\n",
    "\n",
    "# Features and target\n",
    "X = df.iloc[:, :-1].values.astype(float)\n",
    "y = df.iloc[:, -1].values.astype(float)\n",
    "\n",
    "# ------------------ SCALE ------------------\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"âœ… Scaler saved at {scaler_path}\")\n",
    "\n",
    "# ------------------ CREATE SLIDING WINDOWS ------------------\n",
    "X_lstm = []\n",
    "y_lstm = []\n",
    "\n",
    "for i in range(len(X_scaled) - window_size):\n",
    "    X_lstm.append(X_scaled[i:i+window_size, :])\n",
    "    y_lstm.append(y[i+window_size-1])\n",
    "\n",
    "X_lstm = np.array(X_lstm)\n",
    "y_lstm = np.array(y_lstm)\n",
    "\n",
    "# Split into train/validation (80%-20%)\n",
    "split_idx = int(0.8 * len(X_lstm))\n",
    "X_train, y_train = X_lstm[:split_idx], y_lstm[:split_idx]\n",
    "X_val, y_val = X_lstm[split_idx:], y_lstm[split_idx:]\n",
    "\n",
    "print(f\"âœ… Data ready: X_train={X_train.shape}, X_val={X_val.shape}\")\n",
    "\n",
    "# ------------------ BUILD LSTM MODEL ------------------\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    LSTM(64, return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# ------------------ CALLBACKS ------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# ------------------ TRAIN MODEL ------------------\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model saved at {model_path}\")\n",
    "\n",
    "# ------------------ EVALUATE ------------------\n",
    "y_val_pred = model.predict(X_val).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "accuracy = 100 - (rmse / np.max(y_val) * 100)\n",
    "\n",
    "print(f\"\\nðŸ”¹ Model Evaluation â€” FD00{fd_number}\")\n",
    "print(f\"RMSE : {rmse:.4f}\")\n",
    "print(f\"MAE  : {mae:.4f}\")\n",
    "print(f\"RÂ² Score : {r2:.4f}\")\n",
    "print(f\"Approx. Accuracy : {accuracy:.2f}%\")\n",
    "\n",
    "# ------------------ SAVE METRICS ------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"FD_Set\": [f\"FD00{fd_number}\"],\n",
    "    \"RMSE\": [rmse],\n",
    "    \"MAE\": [mae],\n",
    "    \"R2_Score\": [r2],\n",
    "    \"Accuracy(%)\": [accuracy]\n",
    "})\n",
    "results_df.to_csv(os.path.join(results_dir, f\"model_performance_fd{fd_number}_milestone4.csv\"), index=False)\n",
    "print(f\"ðŸ“Š Metrics saved to {results_dir}\")\n",
    "\n",
    "# ------------------ ALERTS ------------------\n",
    "warning_threshold = 50\n",
    "critical_threshold = 20\n",
    "\n",
    "alerts = []\n",
    "for i, rul in enumerate(y_val_pred):\n",
    "    if rul <= critical_threshold:\n",
    "        alerts.append((i, rul, \"CRITICAL\"))\n",
    "    elif rul <= warning_threshold:\n",
    "        alerts.append((i, rul, \"WARNING\"))\n",
    "\n",
    "alert_df = pd.DataFrame(alerts, columns=[\"Sample_Index\", \"Predicted_RUL\", \"Alert_Level\"])\n",
    "alert_df.to_csv(os.path.join(results_dir, f\"alerts_fd{fd_number}_milestone4.csv\"), index=False)\n",
    "print(f\"ðŸ“¢ Alerts saved to {results_dir}\")\n",
    "print(alert_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131efb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
